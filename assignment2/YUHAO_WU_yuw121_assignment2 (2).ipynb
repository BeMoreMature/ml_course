{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<h2>INFSCI 2915 Foundations- Machine Learning - Spring 2018 </h2>\n",
    "<h1 style=\"font-size: 250%;\">Assignment #2</h1>\n",
    "<h3>Issued Monday, 2/26/2018; Due Monday, 11:59pm, 3/12/2018</h3>\n",
    "<h3>Total points: 100 </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type in your information in the double quotes\n",
    "firstName = \"YUHAO\"\n",
    "lastName = \"WU\"\n",
    "pittID = \"yuw121\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Problem #1. Train Test Split [20 points]</h3> \n",
    "In this part, you should download **\"Iris dataset\"**. <br>\n",
    "Use a code below to download the  dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset=load_iris()\n",
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-1. </h4> Split iris dataset into training and test datasets. (use train_test_split function and random_state=0)\n",
    "\n",
    "- Report the shape of each (training and test) datasets. What is the proportion of each set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4)\n",
      "(38, 4)\n",
      "(112,)\n",
      "(38,)\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(dataset['data'],dataset['target'],random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset is near to 75%\n",
    "testset is near to 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-2. </h4>  Split iris dataset into training and test datasets. Make the proportion of training dataset 60% (use train_test_split function and random_state=0)\n",
    " \n",
    "\n",
    "- Report the shape of each (training and test) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(60, 4)\n",
      "(90,)\n",
      "(60,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yuhao wu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(dataset['data'],dataset['target'],train_size=0.6,random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-3. </h4>  Split iris dataset into training and test datasets. Make the proportion of test dataset 33.3% (use train_test_split function and random_state=0)\n",
    "  \n",
    "\n",
    "- Report the shape of each (training and test) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(50, 4)\n",
      "(100,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(dataset['data'],dataset['target'],test_size=0.333,random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-4. Random State </h4> \n",
    "Split iris dataset into training and test datasets, Use different Random State values (0,  10, 253, 1000, 0 and 10) \n",
    "\n",
    "- Analyze the shape and values of the train and test datasets  generated from different Random State values (you can use descriptive statistics) \n",
    "\n",
    "- What happens if you do not specify Random State? \n",
    "\n",
    "- What is a purpose of using Random State? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State is  0\n",
      "(112, 4)\n",
      "(38, 4)\n",
      "(112,)\n",
      "(38,)\n",
      "                0           1           2           3\n",
      "count  112.000000  112.000000  112.000000  112.000000\n",
      "mean     5.886607    3.051786    3.796429    1.222321\n",
      "std      0.871314    0.436196    1.800697    0.782662\n",
      "min      4.300000    2.000000    1.100000    0.100000\n",
      "25%      5.100000    2.800000    1.575000    0.300000\n",
      "50%      5.800000    3.000000    4.250000    1.300000\n",
      "75%      6.500000    3.300000    5.200000    1.900000\n",
      "max      7.900000    4.400000    6.900000    2.500000\n",
      "Random State is  10\n",
      "(112, 4)\n",
      "(38, 4)\n",
      "(112,)\n",
      "(38,)\n",
      "                0           1           2           3\n",
      "count  112.000000  112.000000  112.000000  112.000000\n",
      "mean     5.840179    3.075000    3.716071    1.187500\n",
      "std      0.839397    0.441231    1.794162    0.774611\n",
      "min      4.300000    2.200000    1.000000    0.100000\n",
      "25%      5.100000    2.800000    1.600000    0.300000\n",
      "50%      5.750000    3.000000    4.200000    1.300000\n",
      "75%      6.400000    3.400000    5.100000    1.800000\n",
      "max      7.900000    4.400000    6.900000    2.500000\n",
      "Random State is  253\n",
      "(112, 4)\n",
      "(38, 4)\n",
      "(112,)\n",
      "(38,)\n",
      "                0           1          2           3\n",
      "count  112.000000  112.000000  112.00000  112.000000\n",
      "mean     5.803571    3.066071    3.62500    1.135714\n",
      "std      0.836545    0.428396    1.73727    0.744815\n",
      "min      4.300000    2.200000    1.10000    0.100000\n",
      "25%      5.100000    2.800000    1.50000    0.300000\n",
      "50%      5.700000    3.000000    4.20000    1.300000\n",
      "75%      6.400000    3.225000    5.00000    1.800000\n",
      "max      7.900000    4.400000    6.70000    2.500000\n",
      "Random State is  1000\n",
      "(112, 4)\n",
      "(38, 4)\n",
      "(112,)\n",
      "(38,)\n",
      "                0           1           2           3\n",
      "count  112.000000  112.000000  112.000000  112.000000\n",
      "mean     5.861607    3.075000    3.747321    1.195536\n",
      "std      0.866311    0.418384    1.823123    0.776152\n",
      "min      4.300000    2.300000    1.000000    0.100000\n",
      "25%      5.100000    2.800000    1.500000    0.300000\n",
      "50%      5.800000    3.000000    4.400000    1.300000\n",
      "75%      6.500000    3.400000    5.100000    1.825000\n",
      "max      7.900000    4.200000    6.900000    2.500000\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "import pandas as pd\n",
    "rs=[0,10,253,1000]\n",
    "for index in range(len(rs)):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(dataset['data'],dataset['target'],random_state=rs[index])\n",
    "    print(\"Random State is \",rs[index])\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(Y_test.shape)\n",
    "    df=pd.DataFrame(X_train)\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The shape of each result keep consistent, the values are different.\n",
    "If we don't specify' random state, when we run the code again, the split result maybe change.\n",
    "We use the random state, because we want to make sure the split result keeps consistent each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-5. Optional (Extra Points) </h4> \n",
    "\n",
    "\n",
    "Write a python function that takes the dataset X  (matrix) and Y (numpy array) as an input and returns two non-overlapping datasets: the training and testing data, such that every entry to training set should be selected randomly. The proportion of the training and testing data should be 75%(training)/25%(test). Test your function using the synthetic dataset below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>3000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>400</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>600</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>700</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>800</td>\n",
       "      <td>8000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>900</td>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2   X3    X4  Y\n",
       "0   0   0    0     0  0\n",
       "1   1  10  100  1000  1\n",
       "2   2  20  200  2000  0\n",
       "3   3  30  300  3000  1\n",
       "4   4  40  400  4000  1\n",
       "5   5  50  500  5000  1\n",
       "6   6  60  600  6000  0\n",
       "7   7  70  700  7000  0\n",
       "8   8  80  800  8000  1\n",
       "9   9  90  900  9000  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "X = np.stack((np.arange(100), 10*np.array(np.arange(100)),100*np.array(np.arange(100)),1000*np.array(np.arange(100))), axis=-1)\n",
    "Y = np.random.randint(2, size=100)\n",
    "df = pd.DataFrame(np.concatenate((X,Y[:,None]),axis=1), columns = (\"X1\",\"X2\",\"X3\",\"X4\", \"Y\"))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset \n",
      "\n",
      "     X1   X2    X3     X4  Y_train\n",
      "48  48  480  4800  48000        1\n",
      "6    6   60   600   6000        0\n",
      "99  99  990  9900  99000        1\n",
      "82  82  820  8200  82000        0\n",
      "76  76  760  7600  76000        0\n",
      "60  60  600  6000  60000        0\n",
      "80  80  800  8000  80000        1\n",
      "90  90  900  9000  90000        0\n",
      "68  68  680  6800  68000        1\n",
      "51  51  510  5100  51000        0\n",
      "27  27  270  2700  27000        1\n",
      "18  18  180  1800  18000        0\n",
      "56  56  560  5600  56000        0\n",
      "63  63  630  6300  63000        1\n",
      "74  74  740  7400  74000        0\n",
      "1    1   10   100   1000        1\n",
      "61  61  610  6100  61000        0\n",
      "42  42  420  4200  42000        0\n",
      "41  41  410  4100  41000        0\n",
      "4    4   40   400   4000        1\n",
      "15  15  150  1500  15000        0\n",
      "17  17  170  1700  17000        0\n",
      "40  40  400  4000  40000        1\n",
      "38  38  380  3800  38000        1\n",
      "5    5   50   500   5000        1\n",
      "91  91  910  9100  91000        1\n",
      "59  59  590  5900  59000        1\n",
      "0    0    0     0      0        0\n",
      "34  34  340  3400  34000        1\n",
      "28  28  280  2800  28000        0\n",
      "..  ..  ...   ...    ...      ...\n",
      "19  19  190  1900  19000        0\n",
      "29  29  290  2900  29000        1\n",
      "49  49  490  4900  49000        0\n",
      "97  97  970  9700  97000        1\n",
      "98  98  980  9800  98000        0\n",
      "69  69  690  6900  69000        1\n",
      "20  20  200  2000  20000        1\n",
      "94  94  940  9400  94000        0\n",
      "72  72  720  7200  72000        1\n",
      "77  77  770  7700  77000        0\n",
      "25  25  250  2500  25000        0\n",
      "37  37  370  3700  37000        0\n",
      "81  81  810  8100  81000        1\n",
      "46  46  460  4600  46000        0\n",
      "39  39  390  3900  39000        0\n",
      "65  65  650  6500  65000        0\n",
      "58  58  580  5800  58000        0\n",
      "12  12  120  1200  12000        0\n",
      "88  88  880  8800  88000        0\n",
      "70  70  700  7000  70000        1\n",
      "87  87  870  8700  87000        0\n",
      "36  36  360  3600  36000        1\n",
      "21  21  210  2100  21000        0\n",
      "83  83  830  8300  83000        1\n",
      "9    9   90   900   9000        0\n",
      "96  96  960  9600  96000        0\n",
      "67  67  670  6700  67000        0\n",
      "64  64  640  6400  64000        1\n",
      "47  47  470  4700  47000        1\n",
      "44  44  440  4400  44000        1\n",
      "\n",
      "[75 rows x 5 columns]\n",
      "testset \n",
      "\n",
      "     X1   X2    X3     X4  Y_test\n",
      "26  26  260  2600  26000       0\n",
      "86  86  860  8600  86000       0\n",
      "2    2   20   200   2000       0\n",
      "55  55  550  5500  55000       1\n",
      "75  75  750  7500  75000       0\n",
      "93  93  930  9300  93000       1\n",
      "16  16  160  1600  16000       1\n",
      "73  73  730  7300  73000       1\n",
      "54  54  540  5400  54000       1\n",
      "95  95  950  9500  95000       1\n",
      "53  53  530  5300  53000       1\n",
      "92  92  920  9200  92000       0\n",
      "78  78  780  7800  78000       0\n",
      "13  13  130  1300  13000       1\n",
      "7    7   70   700   7000       0\n",
      "30  30  300  3000  30000       0\n",
      "22  22  220  2200  22000       1\n",
      "24  24  240  2400  24000       0\n",
      "33  33  330  3300  33000       1\n",
      "8    8   80   800   8000       1\n",
      "43  43  430  4300  43000       1\n",
      "62  62  620  6200  62000       0\n",
      "3    3   30   300   3000       1\n",
      "71  71  710  7100  71000       0\n",
      "45  45  450  4500  45000       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yuhao wu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "\n",
    "def split(data):\n",
    "    X=data.iloc[:,0:-1]\n",
    "    Y=data.iloc[:,-1]\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.75,random_state=0)\n",
    "\n",
    "    train=pd.DataFrame(X_train)\n",
    "    train[\"Y_train\"]=Y_train\n",
    "    test=pd.DataFrame(X_test)\n",
    "    test[\"Y_test\"]=Y_test\n",
    "    return (train,test);\n",
    "\n",
    "(train,test)=split(df)\n",
    "print(\"trainset \\n\\n\",train)\n",
    "print(\"testset \\n\\n\",test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Problem #2. Feature Selection  [10 points] </h3>  <br>\n",
    "In this part, you should download and analyze **\"Boston House Prices\" ** dataset **with only 4 features**. <br>\n",
    "(use code below to download  and change dataset)\n",
    "\n",
    "- Find the best two features using forward and backward selection to the Boston House Prices\" dataset with only 4 features ('CHAS','RM','TAX', 'LSTAT'), use a linear regression model to find a best subset of features.\n",
    "- Comment your choice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "dataset = load_boston()\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "#print(dataset.keys())\n",
    "# Data preprocessing\n",
    "new_data= pd.DataFrame(dataset.data, columns=dataset.feature_names)[['CHAS','RM','TAX', 'LSTAT']]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(new_data.values,dataset.target,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score is  0.04897638793034498\n",
      "R2 score is  0.46790005431367815\n",
      "R2 score is  0.09523714508382375\n",
      "R2 score is  0.45763936155604185\n",
      "R2 score is  0.48918314824785486\n",
      "R2 score is  0.43520389313659336\n",
      "R2 score is  0.5692445415835343\n",
      "P-values are:  CHAS      1.900085e-05\n",
      "RM       5.327145e-218\n",
      "TAX       1.657945e-04\n",
      "LSTAT     1.757948e-38\n",
      "dtype: float64\n",
      "P-values are:  CHAS      1.886145e-05\n",
      "RM       9.232978e-259\n",
      "LSTAT     7.363807e-74\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "CHAS_train=X_train[:,0:1]\n",
    "RM_train=X_train[:,1:2]\n",
    "TAX_train=X_train[:,2:3]\n",
    "LSTAT_train=X_train[:,3:4]\n",
    "CHAS_test=X_test[:,0:1]\n",
    "RM_test=X_test[:,1:2]\n",
    "TAX_test=X_test[:,2:3]\n",
    "LSTAT_test=X_test[:,3:4]\n",
    "\n",
    "linreg1=LinearRegression().fit(CHAS_train,Y_train)\n",
    "print(\"R2 score is \",linreg1.score(CHAS_test,Y_test))\n",
    "\n",
    "linreg2=LinearRegression().fit(RM_train,Y_train)\n",
    "print(\"R2 score is \",linreg2.score(RM_test,Y_test))\n",
    "\n",
    "linreg3=LinearRegression().fit(TAX_train,Y_train)\n",
    "print(\"R2 score is \",linreg3.score(TAX_test,Y_test))\n",
    "\n",
    "linreg4=LinearRegression().fit(LSTAT_train,Y_train)\n",
    "print(\"R2 score is \",linreg4.score(LSTAT_test,Y_test))\n",
    "\n",
    "linreg5=LinearRegression().fit(np.concatenate((RM_train,CHAS_train),axis=1),Y_train)\n",
    "print(\"R2 score is \",linreg5.score(np.concatenate((RM_test,CHAS_test),axis=1),Y_test))\n",
    "\n",
    "linreg6=LinearRegression().fit(np.concatenate((RM_train,TAX_train),axis=1),Y_train)\n",
    "print(\"R2 score is \",linreg6.score(np.concatenate((RM_test,TAX_test),axis=1),Y_test))\n",
    "\n",
    "linreg7=LinearRegression().fit(np.concatenate((RM_train,LSTAT_train),axis=1),Y_train)\n",
    "print(\"R2 score is \",linreg7.score(np.concatenate((RM_test,LSTAT_test),axis=1),Y_test))\n",
    "\n",
    "\n",
    "X=new_data\n",
    "Y=dataset.target\n",
    "model = smf.OLS(Y,X)\n",
    "m1=model.fit()\n",
    "print(\"P-values are: \",m1.pvalues)\n",
    "\n",
    "new_data2= pd.DataFrame(dataset.data, columns=dataset.feature_names)[['CHAS','RM', 'LSTAT']]\n",
    "X2=new_data2\n",
    "Y=dataset.target\n",
    "model2 = smf.OLS(Y,X2)\n",
    "m2=model2.fit()\n",
    "print(\"P-values are: \",m2.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forward selection, we calculate the R2 score of each feature, add the feature which has the largest R2 score \n",
    "(In other words, has the lowest RSS ) to model. Then,we add RM and LSTAT to model.\n",
    "Backward selection, we calculate the P-value of each feature, remove the feature which has the largest p-value.\n",
    "Then, we find RM and LSTAT remaining in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Problem #3. Qualitative Variables  [10 points] </h3>\n",
    "\n",
    "In this part, you should download and analyze **\"Boston House Prices\"** dataset. <br>\n",
    "Use a code below to download the  dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "dataset = load_boston()\n",
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #3-1. </h4> Follow steps to answer questions.\n",
    "> *Use train_test_split() with the option \"random_state=0\".\n",
    "\n",
    "- Identify qualitative feature in the dataset (a feature with dummy variable). What is an abbreviation for the qualitative feature? (What is a definition of that  abbreviation ?)\n",
    "\n",
    "- Fit a linear regression model with qualitative variable feature only. Report intercept and coefficient.  \n",
    "\n",
    "- What can you infer about the qualitative feature from the coefficient? (Hint check lecture:  \"Regression with Qualitative Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "[6.320e-03 1.800e+01 2.310e+00 0.000e+00 5.380e-01 6.575e+00 6.520e+01\n",
      " 4.090e+00 1.000e+00 2.960e+02 1.530e+01 3.969e+02 4.980e+00]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-41df4590778b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdummy_majority\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDummyClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'stratified'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy is \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdummy_majority\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\yuhao wu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \"\"\"\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yuhao wu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yuhao wu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "print(dataset.feature_names)\n",
    "print(dataset.data[0])\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_data= pd.DataFrame(dataset.data, columns=dataset.feature_names)[['CHAS']]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(dummy_data,dataset.target,random_state=0)\n",
    "dummy_majority=DummyClassifier(strategy='stratified').fit(X_train, Y_train)\n",
    "print(\"Accuracy is \",dummy_majority.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qualitative feature are CHAS and RAD  \n",
    "- CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- RAD      index of accessibility to radial highways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept is  26.398730760388112\n",
      "Coefficient is  [ 5.88915879 -0.44397195]\n"
     ]
    }
   ],
   "source": [
    "x= pd.DataFrame(dataset.data, columns=dataset.feature_names)[['CHAS','RAD']]\n",
    "y=dataset.target\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(x, y, random_state= 0)\n",
    "linreg= LinearRegression().fit(X_train, Y_train)\n",
    "print(\"Intercept is \",linreg.intercept_)\n",
    "print(\"Coefficient is \",linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We cannot categorize qualitative from the coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Problem #4. Regularization [30 points]  </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-1. </h4> Answer the following questions \n",
    "\n",
    "- What is the objective using regularization?\n",
    "- Do you need to use regularization if you have only 1 feature (B0 and B1)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Write your narrative answer here\n",
    "if number of features is greater than the number of observations, accuracy will degrade.\n",
    "But at many time, we cannot get so many dataset, that is why we need regularization to remove irrelevant features and avoid overfitting.\n",
    "\n",
    "When we only consider about one feature, we do not need to use regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-2.Ridge Regression </h4>  <br>\n",
    "In this part, you should download and analyze **\"Boston House Prices\"** dataset. <br>\n",
    "Use a code below to download the  dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "dataset = load_boston()\n",
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow steps to answer questions.\n",
    "- Fit a linear regression model with all features and report the estimated coefficients for the fitted model (do not just print summary, make a table with feature names and estimated coefficients) \n",
    "-  Fit a ridge regression model with λ = 1. Report the estimated coefficients for the fitted model. \n",
    "-  Fit a ridge regression model with λ = 0. Report the estimated coefficients for the fitted model. \n",
    "- Compare estimated coefficients of ridge regression models with λ = 1 and λ = 0  and linear regression model. (you can use descriptive statistics)\n",
    "- What did you observe from this comparison? \n",
    "- Comment your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 \n",
      "    feature_name  Coefficient\n",
      "0          CRIM    -0.116870\n",
      "1            ZN     0.043994\n",
      "2         INDUS    -0.005348\n",
      "3          CHAS     2.394554\n",
      "4           NOX   -15.629837\n",
      "5            RM     3.761455\n",
      "6           AGE    -0.006950\n",
      "7           DIS    -1.435205\n",
      "8           RAD     0.239756\n",
      "9           TAX    -0.011294\n",
      "10      PTRATIO    -0.986626\n",
      "11            B     0.008557\n",
      "12        LSTAT    -0.500029\n",
      "\n",
      "Question 2 \n",
      "λ = 1, coefficients are \n",
      "    feature_name  Coefficient\n",
      "0          CRIM    -0.113745\n",
      "1            ZN     0.045392\n",
      "2         INDUS    -0.035052\n",
      "3          CHAS     2.304663\n",
      "4           NOX    -8.147359\n",
      "5            RM     3.799228\n",
      "6           AGE    -0.014216\n",
      "7           DIS    -1.336809\n",
      "8           RAD     0.216264\n",
      "9           TAX    -0.011752\n",
      "10      PTRATIO    -0.904760\n",
      "11            B     0.008923\n",
      "12        LSTAT    -0.508385\n",
      "\n",
      "Question 3 \n",
      "λ = 0, coefficients are \n",
      "    feature_name  Coefficient\n",
      "0          CRIM    -0.116870\n",
      "1            ZN     0.043994\n",
      "2         INDUS    -0.005348\n",
      "3          CHAS     2.394554\n",
      "4           NOX   -15.629837\n",
      "5            RM     3.761455\n",
      "6           AGE    -0.006950\n",
      "7           DIS    -1.435205\n",
      "8           RAD     0.239756\n",
      "9           TAX    -0.011294\n",
      "10      PTRATIO    -0.986626\n",
      "11            B     0.008557\n",
      "12        LSTAT    -0.500029\n",
      "\n",
      "Question 4 \n",
      "    feature_name  Coefficient_x  Coefficient_y  Coefficient\n",
      "0          CRIM      -0.116870      -0.113745    -0.116870\n",
      "1            ZN       0.043994       0.045392     0.043994\n",
      "2         INDUS      -0.005348      -0.035052    -0.005348\n",
      "3          CHAS       2.394554       2.304663     2.394554\n",
      "4           NOX     -15.629837      -8.147359   -15.629837\n",
      "5            RM       3.761455       3.799228     3.761455\n",
      "6           AGE      -0.006950      -0.014216    -0.006950\n",
      "7           DIS      -1.435205      -1.336809    -1.435205\n",
      "8           RAD       0.239756       0.216264     0.239756\n",
      "9           TAX      -0.011294      -0.011752    -0.011294\n",
      "10      PTRATIO      -0.986626      -0.904760    -0.986626\n",
      "11            B       0.008557       0.008923     0.008557\n",
      "12        LSTAT      -0.500029      -0.508385    -0.500029\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "x=dataset.data\n",
    "y=dataset.target\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(x, y, random_state= 0)\n",
    "linreg= LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "ft=pd.DataFrame(dataset.feature_names,columns=['feature_name'])\n",
    "ft[\"Coefficient\"]=linreg.coef_\n",
    "print(\"Question 1 \\n\",ft)\n",
    "\n",
    "RidgeModel=Ridge().fit(X_train,Y_train)\n",
    "ft1=pd.DataFrame(dataset.feature_names,columns=['feature_name'])\n",
    "ft1[\"Coefficient\"]=RidgeModel.coef_\n",
    "print(\"\\nQuestion 2 \\nλ = 1, coefficients are \\n\",ft1)\n",
    "\n",
    "RidgeModel0=Ridge(alpha=0).fit(X_train,Y_train)\n",
    "ft0=pd.DataFrame(dataset.feature_names,columns=['feature_name'])\n",
    "ft0[\"Coefficient\"]=RidgeModel0.coef_\n",
    "print(\"\\nQuestion 3 \\nλ = 0, coefficients are \\n\",ft0)\n",
    "\n",
    "df=pd.merge(ft,ft1,how='left',on=['feature_name'])\n",
    "dff=pd.merge(df,ft0,how='left',on=['feature_name'])\n",
    "print(\"\\nQuestion 4 \\n\",dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "When λ = 0, RidgeRegression coefficient is equal to the liner regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-3.Ridge Regression (part 2) </h4>  <br>\n",
    "Fit a ridge regression with λ = 5, 10, 50, 100, and 1000. For each value, report the estimated coefficients for the fitted model (do not just print summary, make a DataFrame with feature names and estimated coefficients)\n",
    "- What happens to the coefficients as you increase λ?\n",
    "- What happens to the flexibility of the model as you increase λ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_name  Coefficient_x  Coefficient_y  Coefficient_x  Coefficient_y  \\\n",
      "0          CRIM      -0.111712      -0.111268      -0.108919      -0.105931   \n",
      "1            ZN       0.046949       0.047930       0.051976       0.053887   \n",
      "2         INDUS      -0.055871      -0.060710      -0.067184      -0.067772   \n",
      "3          CHAS       1.982748       1.687262       0.785963       0.481930   \n",
      "4           NOX      -2.802456      -1.543206      -0.334039      -0.163467   \n",
      "5            RM       3.706435       3.549560       2.616806       1.982008   \n",
      "6           AGE      -0.018374      -0.018206      -0.010997      -0.004330   \n",
      "7           DIS      -1.268301      -1.252946      -1.214426      -1.154603   \n",
      "8           RAD       0.204486       0.206644       0.230319       0.244168   \n",
      "9           TAX      -0.012292      -0.012622      -0.013786      -0.014375   \n",
      "10      PTRATIO      -0.853248      -0.847922      -0.869840      -0.879572   \n",
      "11            B       0.009170       0.009193       0.008829       0.008457   \n",
      "12        LSTAT      -0.523201      -0.536472      -0.604153      -0.648463   \n",
      "\n",
      "    Coefficient  \n",
      "0     -0.086351  \n",
      "1      0.054640  \n",
      "2     -0.047192  \n",
      "3      0.073313  \n",
      "4     -0.006844  \n",
      "5      0.441204  \n",
      "6      0.026831  \n",
      "7     -0.548033  \n",
      "8      0.231527  \n",
      "9     -0.015109  \n",
      "10    -0.650367  \n",
      "11     0.007257  \n",
      "12    -0.729129  \n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "para=[5,10,50,100,1000]\n",
    "rdf=pd.DataFrame(dataset.feature_names,columns=['feature_name'])\n",
    "for index in range(len(para)):\n",
    "    \n",
    "    RidgeModel=Ridge(alpha=para[index]).fit(X_train,Y_train)\n",
    "    ft=pd.DataFrame(dataset.feature_names,columns=['feature_name'])\n",
    "    ft[\"Coefficient\"]=RidgeModel.coef_\n",
    "#     print(\"λ = \",para[index], \"coefficients are \\n\",ft)\n",
    "    rdf=pd.merge(rdf,ft,how='left',on=['feature_name'])\n",
    "    \n",
    "print(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "When increasing the λ, the coefficient keep getting close to zero\n",
    "flexibility of the model decreases, the model became less complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-4 Lasso Regression </h4>  <br>\n",
    "In this part, you should download and analyze **\"Boston House Prices\"** dataset. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow steps to answer questions.\n",
    "- Fit a linear regression model with all features and report the estimated coefficients for the fitted model (do not just print summary, make a DataFrame with feature names and estimated coefficients) \n",
    "-  Fit a lasso regression model with λ = 1. Report the estimated coefficients for the fitted model. \n",
    "-  Fit a lasso regression model with λ = 0. Report the estimated coefficients for the fitted model. \n",
    "- Compare estimated coefficients of lasso regression models with λ = 1 and λ = 0, ridge regression models with λ = 1 and λ = 0 and linear regression model. (you can use descriptive statistics)\n",
    "\n",
    "- What did you observe from this comparison? \n",
    "\n",
    "- Comment your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 \n",
      "    feature_name  Coefficient\n",
      "0          CRIM    -0.116870\n",
      "1            ZN     0.043994\n",
      "2         INDUS    -0.005348\n",
      "3          CHAS     2.394554\n",
      "4           NOX   -15.629837\n",
      "5            RM     3.761455\n",
      "6           AGE    -0.006950\n",
      "7           DIS    -1.435205\n",
      "8           RAD     0.239756\n",
      "9           TAX    -0.011294\n",
      "10      PTRATIO    -0.986626\n",
      "11            B     0.008557\n",
      "12        LSTAT    -0.500029\n",
      "\n",
      "Question 2 \n",
      "λ = 1, coefficients are \n",
      "    feature_name  Coefficient\n",
      "0          CRIM    -0.059218\n",
      "1            ZN     0.050014\n",
      "2         INDUS    -0.001553\n",
      "3          CHAS     0.000000\n",
      "4           NOX    -0.000000\n",
      "5            RM     0.758533\n",
      "6           AGE     0.013051\n",
      "7           DIS    -0.710499\n",
      "8           RAD     0.195772\n",
      "9           TAX    -0.014148\n",
      "10      PTRATIO    -0.805582\n",
      "11            B     0.007156\n",
      "12        LSTAT    -0.742312\n",
      "\n",
      "Question 3 \n",
      "λ = 0, coefficients are \n",
      "    feature_name  Coefficient\n",
      "0          CRIM    -0.116870\n",
      "1            ZN     0.043994\n",
      "2         INDUS    -0.005348\n",
      "3          CHAS     2.394554\n",
      "4           NOX   -15.629837\n",
      "5            RM     3.761455\n",
      "6           AGE    -0.006950\n",
      "7           DIS    -1.435205\n",
      "8           RAD     0.239756\n",
      "9           TAX    -0.011294\n",
      "10      PTRATIO    -0.986626\n",
      "11            B     0.008557\n",
      "12        LSTAT    -0.500029\n",
      "\n",
      "Question 4 \n",
      "    feature_name  Coefficient_x  Coefficient_y  Coefficient\n",
      "0          CRIM      -0.116870      -0.059218    -0.116870\n",
      "1            ZN       0.043994       0.050014     0.043994\n",
      "2         INDUS      -0.005348      -0.001553    -0.005348\n",
      "3          CHAS       2.394554       0.000000     2.394554\n",
      "4           NOX     -15.629837      -0.000000   -15.629837\n",
      "5            RM       3.761455       0.758533     3.761455\n",
      "6           AGE      -0.006950       0.013051    -0.006950\n",
      "7           DIS      -1.435205      -0.710499    -1.435205\n",
      "8           RAD       0.239756       0.195772     0.239756\n",
      "9           TAX      -0.011294      -0.014148    -0.011294\n",
      "10      PTRATIO      -0.986626      -0.805582    -0.986626\n",
      "11            B       0.008557       0.007156     0.008557\n",
      "12        LSTAT      -0.500029      -0.742312    -0.500029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yuhao wu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "c:\\users\\yuhao wu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "c:\\users\\yuhao wu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "x=dataset.data\n",
    "y=dataset.target\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(x, y, random_state= 0)\n",
    "linreg= LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "ft=pd.DataFrame(dataset.feature_names,columns=['feature_name'])\n",
    "ft[\"Coefficient\"]=linreg.coef_\n",
    "print(\"Question 1 \\n\",ft)\n",
    "\n",
    "LassoModel=Lasso().fit(X_train,Y_train)\n",
    "ft1=pd.DataFrame(dataset.feature_names,columns=['feature_name'])\n",
    "ft1[\"Coefficient\"]=LassoModel.coef_\n",
    "print(\"\\nQuestion 2 \\nλ = 1, coefficients are \\n\",ft1)\n",
    "\n",
    "LassoModel0=Lasso(alpha=0).fit(X_train,Y_train)\n",
    "ft0=pd.DataFrame(dataset.feature_names,columns=['feature_name'])\n",
    "ft0[\"Coefficient\"]=LassoModel0.coef_\n",
    "print(\"\\nQuestion 3 \\nλ = 0, coefficients are \\n\",ft0)\n",
    "\n",
    "df=pd.merge(ft,ft1,how='left',on=['feature_name'])\n",
    "dff=pd.merge(df,ft0,how='left',on=['feature_name'])\n",
    "print(\"\\nQuestion 4 \\n\",dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "When λ = 0, LassoRegression coefficient is equal to the liner regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-5.Lasso Regression (part 2) </h4>  <br>\n",
    "Fit a lasso regression with λ = 5, 10, 50, 100, and 1000. For each value, report the estimated coefficients for the fitted model (do not just print summary, make a DataFrmae with feature names and estimated coefficients)\n",
    "- What happens to the coefficients as you increase λ?\n",
    "- What happens to the flexibility of the model as you increase λ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_name  Coefficient_x  Coefficient_y  Coefficient_x  Coefficient_y  \\\n",
      "0          CRIM      -0.000000      -0.000000      -0.000000      -0.000000   \n",
      "1            ZN       0.043374       0.032687       0.003385       0.000000   \n",
      "2         INDUS      -0.000000      -0.000000      -0.000000      -0.000000   \n",
      "3          CHAS       0.000000       0.000000       0.000000       0.000000   \n",
      "4           NOX       0.000000       0.000000      -0.000000      -0.000000   \n",
      "5            RM       0.000000       0.000000       0.000000       0.000000   \n",
      "6           AGE       0.029813       0.000000      -0.000000      -0.000000   \n",
      "7           DIS      -0.000000      -0.000000       0.000000       0.000000   \n",
      "8           RAD       0.000000       0.000000       0.000000      -0.000000   \n",
      "9           TAX      -0.010010      -0.011559      -0.023138      -0.022912   \n",
      "10      PTRATIO      -0.000000      -0.000000      -0.000000      -0.000000   \n",
      "11            B       0.004907       0.006793       0.010789       0.004822   \n",
      "12        LSTAT      -0.732126      -0.549712      -0.000000      -0.000000   \n",
      "\n",
      "    Coefficient  \n",
      "0          -0.0  \n",
      "1           0.0  \n",
      "2          -0.0  \n",
      "3           0.0  \n",
      "4          -0.0  \n",
      "5           0.0  \n",
      "6          -0.0  \n",
      "7           0.0  \n",
      "8          -0.0  \n",
      "9          -0.0  \n",
      "10         -0.0  \n",
      "11          0.0  \n",
      "12         -0.0  \n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "para=[5,10,50,100,1000]\n",
    "ldf=pd.DataFrame(dataset.feature_names,columns=['feature_name'])\n",
    "for index in range(len(para)):\n",
    "    \n",
    "    LassoModel=Lasso(alpha=para[index]).fit(X_train,Y_train)\n",
    "    ft=pd.DataFrame(dataset.feature_names,columns=['feature_name'])\n",
    "    ft[\"Coefficient\"]=LassoModel.coef_\n",
    "#     print(\"λ = \",para[index], \"coefficients are \\n\",ft)\n",
    "    ldf=pd.merge(ldf,ft,how='left',on=['feature_name'])\n",
    "    \n",
    "print(ldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "When increasing the λ, the coefficient is equal to zero\n",
    "flexibility of the model decreases, the model became less complex, just relate to some features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>  Problem #5.Logistic Regression [30 points] </h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #5-1. </h4>  <br>\n",
    "We fit a logistic regression model to predict the probability that an individual will default on his/her credit card balance. We used the total balance (single feature) to fit the model and got the results shown in the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|        |Coefficient| Std.error|Z -statistic|P-Value|\n",
    "|:--:|:-------------------------------:|\n",
    "|Intercept|-10.6513|0.3612|-29.5|<0.0001|\n",
    "|balance|0.0055|0.002|24.9|<0.0001|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the parametric model used in logistic regression?\n",
    "- What is the probability that an individual with a balance equal to 15000 dollar will default?\n",
    "- What is the probability that an individual with balance equals to 800 dollar will not default?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We use probability=(math.exp(-10.6513+0.0055*X))/(1+math.exp(-10.6513+0.0055*X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2\n",
      " 15000 dollar, probability is  1.0\n",
      "Question 3\n",
      " 800 dollar, probability is  0.0019242363522599308\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "\n",
    "p1=(math.exp(-10.6513+0.0055*15000))/(1+math.exp(-10.6513+0.0055*15000))\n",
    "print(\"Question 2\\n 15000 dollar, probability is \",p1)\n",
    "p2=(math.exp(-10.6513+0.0055*800))/(1+math.exp(-10.6513+0.0055*800))\n",
    "print(\"Question 3\\n 800 dollar, probability is \",p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #5-2. </h4>  <br>\n",
    "\n",
    "The coefficients of logistic regression are obtained by maximizing the likelihood function\n",
    "\n",
    "\\begin{array} \\\\\n",
    "l(\\beta) = \\prod_{i:y_{i}=1} P(y_{i} = 1|x)\\prod_{i{}':y_{{i}'}=0} (1-P(y_{{i}'} = 1|x))\n",
    "\\end{array}\n",
    "Show that maximizing the\n",
    "likelihood function is equivalent to minimizing the cost function $J(\\beta)$, such that.\n",
    "\\begin{array} \\\\\n",
    "J(\\beta) = -\\sum [y_{i} log(P(y_{i} = 1|x)) + (1- y_{i})log(1- P(y_{i} = 1|x))]\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "Here $n$ is the number training examples. Mention one possible method for obtaining the\n",
    "optimal coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Write your narrative answer here\n",
    "Learning:\tFour approaches to solving\tobjective:\t\n",
    "We\tcan\talso\tapply\tSGD\tto\tsolve\tthe\tMCLE\t\n",
    "problem\tfor\tLogistic regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
