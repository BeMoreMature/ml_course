{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<h2>INFSCI 2915 Foundations- Machine Learning - Spring 2018 </h2>\n",
    "<h1 style=\"font-size: 250%;\">Assignment #3</h1>\n",
    "<h3>Issued Monday, 3/26/2018; Due Monday, 11:59pm, 4/09/2018</h3>\n",
    "<h3>Total points: 100 </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Type in your information in the double quotes\n",
    "firstName = \"\"\n",
    "lastName = \"\"\n",
    "pittID = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Problem #1.Linear Discriminant Analysis (LDA)and Quadratic Discriminant Analysis(QDA)      <br>[30 points]</h3> \n",
    " Writing a code is not required for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-1</h4>  <br>\n",
    "Assume we have K classes to be classified with one feature $(x)$. The prior probability of\n",
    "class $k$ is $ùúã_{k} = ùëÉ(ùëå = ùëò)$. Assume that the feature in class k has Gaussian distribution of\n",
    "mean $Œº_{k}$ and variance $œÉ^2 (ùí©(Œº,ùúé^{2}))$.The variance is the same for all classes. \n",
    "Prove that the Bayes‚Äô classifier (that chooses class k with largest $ùëÉ(ùëå = ùëò|ùë•))$ is equivalent to assigning an observation to the class for which the discriminant function $ùõø_{k}(x)$ is\n",
    "maximized, where \n",
    "\\begin{array} \\\\\n",
    "ùõø_{k}(x) = x\\frac{\\mu _{k}}{\\sigma ^{2}}- \\frac{\\mu_{2}^{k}}{2\\sigma ^{2}}+ log(\\pi _{k})\n",
    "\\end{array}\n",
    "<br> What is the name of this classifier?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your narrative answer here (no code is needed for this part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-2</h4>  <br>\n",
    "Extend **Problem #1-1** to include **p** features. With features from each class drawn from a\n",
    "Gaussian distribution with mean vector $Œº_{k}$ and covariance matrix $Œ£_{k}$ (which is now\n",
    "different for each class). Find the discriminant function that maximizes **ùëÉ(ùëå = ùëò|ùë•)**. Is\n",
    "the relationship with the feature vector **x** linear?<br> What is this classifier?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your narrative answer here (no code is needed for this part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-3</h4>  <br>\n",
    "- Explain Bias-variance trade-off in choosing between LDA and QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your narrative answer here (no code is needed for this part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Problem #2. Support Vector Machines  [20 points]</h3> \n",
    "Writing a code is not required for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #2-1 Answer the following quesionts </h4> \n",
    "\n",
    "- Describe limitations of using Maximal Margin Classifier \n",
    "- What is the difference between Support Vector Classifier and Maximal Margin Classifier\n",
    "- Explain Bias-variance trade-off that occurs when we choose large and small values for the Slack Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your narrative answer here (no code is needed for this part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #2-2</h4><br>\n",
    "How does the Radial Basis Function Kernel in SVM measure the similarity between a test point and a training example? Discuss the impact of choosing a large RBF parameter **ùõæ**\n",
    "on the learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your narrative answer here (no code is needed for this part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Problem #3 Classification Performance Evaluation and Cross validation [30 points]</h3> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #3-1</h4> <br>\n",
    "In a fraud detection system, a QDA classifier‚Äôs confusion matrix is found to be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|        |Predicted Class - Not fraud| Predicted Class - fraud|\n",
    "|:--:|:-------------------------------:|\n",
    "|Actual class ‚Äì Not fraud|1000|20|\n",
    "|Actual class ‚Äì fraud|30|5|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate the overall error rate and the accuracy<br>\n",
    "- Evaluate the precision and the recall <br>\n",
    "- Is dataset balanced?\n",
    "- Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your narrative answer here (no code is needed for this part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #3-2</h4> <br>\n",
    "Assuming we want to lower the misclassification of fraud. How can you modify the classifier to do better classification using information from confusion matrix? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your narrative answer here (no code is needed for this part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #3-3 Cross validation, SVM </h4> <br>\n",
    "In this exercise, we will use SVM  for breast cancer classification (malignant or benign).<br> \n",
    "Use a code below to download the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer()\n",
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow steps to answer questions.\n",
    "- Scale the features with MinMaxScaler\n",
    "- Split breast cancer dataset into two, test dataset and train dataset\n",
    "- Find best SVM classifier model. Try values of C=[0.001, 0.1, 1, 10, 1000] and Gamma = [0.001, 0.1, 1, 10, 1000]. \n",
    "- Use 3-fold cross validation to find the best parameters (using all possible combinations of these values for C and gamma).\n",
    "- Report your parameters\n",
    "- Report accuracy, confusion matrix, precision, and recall (use Test dataset, SVM classifier model with best parameters)\n",
    "- Comment your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #3-4 Cross validation, Logistic regression </h4>\n",
    "\n",
    "- Repeat **Problem #3-3** but instead of SVM find best Logistic regression classifier model. Try values of C= [0.001,0.01,1,10,100, 1000] and Penalty = [\"l1\",\"l2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Problem #4  Neural Networks [20 points]</h3> \n",
    "In this exercise we will clasify Iris species (Setosa, Versicolor, Virginica) using Neural Networks.<br>\n",
    "Use a code below to download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset=load_iris()\n",
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow steps to answer questions.\n",
    "- Scale the feautures with MinMaxScaler, then use sklearn MLPClassifier. \n",
    "- Build a model that has two hidden layers, the first layer has 10 neurons and second layer has 5 neurons. \n",
    "- Use 'relu' activation function, and set the regularization parameter alpha=0.5. \n",
    "- Set the random_state=0 for splitting and building all models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-1 </h4>\n",
    "- Use gradient descent to solve the optimization  problem (i.e. get the weights), and choose random_state=0 (which corresponds to a particular initializationo of weight values). \n",
    "- Report accuracy, confusion matrix, precision, and recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-2 </h4>\n",
    "- Repeat **Problem #4-1** but with a model that use random_state=10 to initialize the weights. \n",
    "- Report accuracy, confusion matrix, precision, and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-3 </h4>\n",
    "- Repeat **Problem #4-2** but with model that use L-BFGS (a numerical quasi-Newton method) instead of stochastic gradient descent to find the weights.\n",
    "- Report accuracy, confusion matrix, precision, and recall\n",
    "- Comment on results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
